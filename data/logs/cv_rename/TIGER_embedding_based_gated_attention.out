TIGER embedding_based gated_attention

INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (517) bind mounts
Args parsed!
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 1/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 2/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 3/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.3125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 4/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 5/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.25
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 6/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 7/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 8/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 9/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 10/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 11/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.25
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 12/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 13/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 14/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 15/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 16/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 17/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 18/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 19/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.25
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 20/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 21/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.3125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 22/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 23/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 24/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 25/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 26/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 27/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 28/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 29/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 30/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 31/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 32/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 33/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 34/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 35/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 36/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 37/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 38/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 39/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 40/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 41/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 42/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.3125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 43/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 44/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 45/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 46/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 47/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 48/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 49/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 50/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 51/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 52/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5625
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 53/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 54/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 55/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 56/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 57/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 58/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 59/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 60/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.25
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 61/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 62/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 63/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 64/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 65/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 66/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 67/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 68/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.0625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 69/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 70/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 71/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 72/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 73/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 74/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 75/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 76/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.25
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 77/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 78/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 79/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 80/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 81/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 82/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 83/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 84/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 85/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 86/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 87/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 88/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.25
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 89/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 90/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 91/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.3125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 92/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 93/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 94/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 95/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 96/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 97/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 98/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 99/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 100/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 101/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 102/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 103/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 104/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 105/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 106/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 107/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 108/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 109/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 110/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 111/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 112/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 113/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 114/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 115/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 116/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 117/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 118/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 119/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 120/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 121/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 122/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 123/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 124/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 125/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 126/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 127/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 128/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 129/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 130/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 131/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 132/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 133/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 134/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 135/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 136/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 137/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 138/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 139/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 140/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 141/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 142/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 143/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 144/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 145/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 146/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 147/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 148/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 149/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.1875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 150/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 151/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 152/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 153/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 154/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 155/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 156/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 157/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.1875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 158/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 159/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.25
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 160/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 161/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 162/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.1875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 163/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 164/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 165/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 166/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 167/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 168/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 169/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 170/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 171/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 172/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 173/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 174/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 175/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 176/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.1875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 177/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 178/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.25
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 179/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 180/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 181/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 182/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 183/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 184/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 185/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 186/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 187/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 188/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 189/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 190/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 191/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 192/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 193/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 194/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 195/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 196/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 197/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 198/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 199/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 200/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 201/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 202/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.25
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 203/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 204/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 205/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 206/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.3125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 207/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 208/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.3125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 209/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 210/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 211/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 212/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 213/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 214/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 215/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 216/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 217/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 218/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 219/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.1875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 220/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 221/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 222/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 223/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 224/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 225/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 226/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 227/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 228/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 229/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 230/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 231/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 232/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 233/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 234/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 235/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 236/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 237/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 238/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 239/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 240/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 241/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.1875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 242/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 243/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 244/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 245/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.3125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 246/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.1875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 247/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.1875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.25
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 248/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 249/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 250/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 251/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.1875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 252/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 253/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.1875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 254/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.1875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 255/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 256/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.25
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 257/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 258/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.3125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 259/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 260/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.1875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 261/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.25
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 262/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.0625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.3125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 263/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.25
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 264/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.0625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 265/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 266/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 267/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 268/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 269/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 270/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 271/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 272/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 273/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 274/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 275/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 276/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 277/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 278/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.1875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.25
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 279/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 280/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.1875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 281/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 282/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 283/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 284/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.1875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 285/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.3125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 286/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 287/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'} - 288/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
CV found the following parameter combination: {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'gated_attention'}
Test Accuracy: 0.77500
precision: 0.77273
recall: 0.80952
F-Score: 0.79070
AUC: 0.77318
Predictions on test set: [1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.
 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0.]
