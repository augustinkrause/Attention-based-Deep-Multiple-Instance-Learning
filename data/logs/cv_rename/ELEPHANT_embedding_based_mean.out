ELEPHANT embedding_based mean

INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (517) bind mounts
Args parsed!
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 1/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 2/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 3/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 4/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 5/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 6/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 7/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 8/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 9/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 10/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 11/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 12/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 13/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 14/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 15/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 16/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5625
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 17/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 18/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 19/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 20/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 21/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 22/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 23/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 24/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 25/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 26/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 27/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 28/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 29/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 30/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 31/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 32/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 33/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 34/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 35/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 36/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 37/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 38/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 39/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 40/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 41/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 42/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 43/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 44/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 45/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 46/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 47/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 48/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 49/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.75
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 50/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 51/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 52/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5625
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 53/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 54/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 55/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 56/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 57/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 1.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.75
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 58/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 59/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 60/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 61/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.75
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 62/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 63/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 64/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 65/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.75
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 66/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 67/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 68/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 69/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 70/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 71/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 72/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 73/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 74/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.75
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 75/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 76/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 77/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 78/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 79/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 80/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.75
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 81/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 82/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 83/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 84/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 85/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.25
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 86/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 87/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 88/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 89/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 90/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 91/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 92/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 93/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 94/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 95/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 96/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 97/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.9375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 98/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 99/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 100/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.3125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 101/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 102/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 103/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 104/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 105/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 106/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 107/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.9375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 108/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.6875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 109/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.9375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 110/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.3125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 111/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 112/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 113/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 114/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 115/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 116/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 117/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 118/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.4375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.6875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 119/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 120/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 121/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.9375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 122/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.8125
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 123/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 124/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 125/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 126/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 127/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 128/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 129/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 130/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.4375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 131/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 132/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 133/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 134/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 135/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 136/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 137/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 138/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 139/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 140/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 141/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 142/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 143/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 144/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 145/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 146/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 147/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 148/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.75
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 149/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.9375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 150/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 151/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 152/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 153/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 154/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 155/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 156/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 157/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.75
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 158/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 159/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 160/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 161/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 1.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 162/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 163/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 164/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 165/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 166/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 167/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 168/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 169/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 170/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 171/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 172/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 173/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 174/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 175/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 176/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 177/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 178/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 179/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 180/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 181/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 182/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.9375
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 183/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 184/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 185/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.4375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 186/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 187/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 188/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 189/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 190/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 191/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 192/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 193/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 194/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.4375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 195/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 196/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.3125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 197/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 198/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 199/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.9375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 200/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.6875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 201/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.9375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 202/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 203/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.9375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 204/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.9375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 205/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 206/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.4375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 207/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.9375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 208/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.4375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 209/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 210/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 211/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 212/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.6875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 213/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 214/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.4375
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 215/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 216/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 217/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 218/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.75
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 219/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 220/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 221/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 222/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 223/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 224/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 225/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.9375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 226/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 227/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.75
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 228/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 229/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.6875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 230/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 231/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 232/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 233/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 234/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 235/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 236/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5625
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 237/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 238/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 239/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 240/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 241/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 242/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 243/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 244/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 245/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 246/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 247/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.6875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.6875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.875
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 248/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 249/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.6875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.625
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 250/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 251/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 252/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.4375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 253/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.75
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 254/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.875
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 255/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8125
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.875
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.8125
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 256/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.875
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8125
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 257/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.8125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.6875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 258/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.8125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.8125
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 259/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 260/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 261/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 262/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 263/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 264/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 265/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 266/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 267/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 268/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 269/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 270/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 271/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 272/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.875
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 273/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.75
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 274/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 1.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.875
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 275/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 276/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.4375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 277/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 278/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.75
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.75
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.9375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.6875
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 279/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 280/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.8125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.6875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8125
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.9375
In partition number 6/10
Beginning training
Loss after CV iteration 6: 1.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.9375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.9375
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.75
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 281/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.3125
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 282/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 283/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.6875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5625
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 284/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 285/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 286/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 287/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5625
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.625
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.375
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.375
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'embedding_based', 'pooling_type': 'mean'} - 288/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.4375
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.375
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.375
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5625
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.625
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.6875
CV found th following parameter combination: {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'embedding_based', 'pooling_type': 'mean'}
Test Accuracy: 0.55000
precision: 0.53846
recall: 1.00000
F-Score: 0.70000
AUC: 0.52632
Predictions on test set: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
