MUSK1 instance_based max

INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (517) bind mounts
Args parsed!
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 1/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.7142857142857143
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 2/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8571428571428571
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 3/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8571428571428571
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 4/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 5/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 6/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8571428571428571
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 7/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.7142857142857143
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 8/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 9/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.7142857142857143
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 10/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.7142857142857143
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 11/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 12/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 13/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 14/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 15/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.0
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 16/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 17/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 18/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 19/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 20/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8571428571428571
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 21/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 22/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.0
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8571428571428571
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 23/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 24/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 25/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 26/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 27/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 28/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 29/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 30/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 31/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 32/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 33/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 34/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 35/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 36/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 37/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 38/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 39/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 40/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.875
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 41/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 42/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 43/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 44/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 45/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 46/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 47/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 48/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 49/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 50/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 51/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 52/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 53/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 54/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 55/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 56/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 57/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.8571428571428571
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 58/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.0
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 59/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 60/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 61/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 62/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 63/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 64/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 65/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 66/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 67/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 68/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 69/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 70/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 71/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 72/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 73/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 74/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 75/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 76/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 77/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 78/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 79/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 80/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.0
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 81/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 82/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 83/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 84/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 85/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 86/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 87/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 88/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 89/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 90/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 91/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 92/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 93/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 94/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 95/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 1, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 96/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 97/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 98/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 99/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 100/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 101/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 102/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 103/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 104/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.8571428571428571
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 105/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 106/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 107/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 108/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 109/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 110/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.75
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 111/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 112/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 113/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 114/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.0
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 115/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 116/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 117/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 118/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 119/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 120/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.7142857142857143
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 121/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 122/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 123/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 124/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 125/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 126/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 127/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 128/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 129/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 130/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 131/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 132/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 133/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 134/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 135/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 136/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 137/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 138/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 139/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 140/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 141/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 142/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 143/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 144/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 145/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 146/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 147/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.14285714285714285
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 148/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.14285714285714285
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 149/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 150/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 151/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 152/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 153/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 154/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 155/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 156/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 157/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.75
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 158/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 159/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 160/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 161/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 162/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 163/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 164/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 165/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.7142857142857143
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 166/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 167/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 168/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 169/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 170/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 171/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 172/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 173/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 174/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 175/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 176/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 177/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 178/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 179/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 180/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 181/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 182/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 183/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 184/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 185/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 186/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 187/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 188/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 189/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 190/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 191/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 10, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 192/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 193/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 194/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.75
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.7142857142857143
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 195/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.14285714285714285
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 196/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 197/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 198/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 199/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 200/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 201/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 202/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.5714285714285714
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 203/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 204/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 205/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 206/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.8571428571428571
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 207/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 208/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 209/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 210/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 211/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 212/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.5
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 213/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 214/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.5
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.0
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 215/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.0001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 216/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.0
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 217/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 218/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 219/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.0
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 220/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 221/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 222/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 223/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 224/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 225/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 226/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 227/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 228/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 229/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 230/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 231/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 232/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 233/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 234/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 235/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 236/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 237/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 238/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.125
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 239/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.001, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 240/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.0
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 241/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 242/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 243/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 244/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 245/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 246/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 247/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.7142857142857143
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 248/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 249/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.42857142857142855
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 250/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.14285714285714285
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 251/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 1.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 252/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 253/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.375
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.7142857142857143
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 254/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 255/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 256/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.14285714285714285
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 257/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.5714285714285714
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 258/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 259/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 260/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 261/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 262/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.0
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 263/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.5
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 264/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.125
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.25
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.0
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.14285714285714285
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.2857142857142857
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.0
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 265/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 266/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 267/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 268/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 269/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 270/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 271/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 272/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.2857142857142857
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 273/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 274/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 275/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 276/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 277/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 278/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 279/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 280/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.14285714285714285
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 281/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.005, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 282/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 283/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.875
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.42857142857142855
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.7142857142857143
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 284/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.0
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.14285714285714285
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.2857142857142857
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 285/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.625
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.2857142857142857
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.7142857142857143
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.8571428571428571
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 286/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.25
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.25
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.14285714285714285
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.2857142857142857
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.5714285714285714
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.2857142857142857
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.42857142857142855
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'Adam', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 287/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.375
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.625
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.2857142857142857
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.42857142857142855
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.42857142857142855
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.42857142857142855
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.42857142857142855
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
Testing for parameter combination {'n_epochs': 100, 'learning_rate': 0.1, 'weight_decay': 0.05, 'momentum': 0.9, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'} - 288/288

In partition number 1/10
Beginning training
Loss after CV iteration 1: 0.625
In partition number 2/10
Beginning training
Loss after CV iteration 2: 0.375
In partition number 3/10
Beginning training
Loss after CV iteration 3: 0.125
In partition number 4/10
Beginning training
Loss after CV iteration 4: 0.7142857142857143
In partition number 5/10
Beginning training
Loss after CV iteration 5: 0.5714285714285714
In partition number 6/10
Beginning training
Loss after CV iteration 6: 0.5714285714285714
In partition number 7/10
Beginning training
Loss after CV iteration 7: 0.7142857142857143
In partition number 8/10
Beginning training
Loss after CV iteration 8: 0.5714285714285714
In partition number 9/10
Beginning training
Loss after CV iteration 9: 0.5714285714285714
In partition number 10/10
Beginning training
Loss after CV iteration 10: 0.14285714285714285
CV found the following parameter combination: {'n_epochs': 100, 'learning_rate': 0.01, 'weight_decay': 0.005, 'momentum': 0.09, 'beta_1': 0.9, 'beta_2': 0.999, 'optimizer': 'SGD', 'mil_type': 'instance_based', 'pooling_type': 'max'}
Test Accuracy: 0.78947
precision: 0.88889
recall: 0.72727
F-Score: 0.80000
AUC: 0.80114
Predictions on test set: [1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.]
